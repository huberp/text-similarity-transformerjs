# Output Examples

This document provides examples of the CSV outputs generated by the similarity analysis script.

## embeddings.csv

This file contains the document embeddings with metadata. Each row represents one document.

**Format:**
```csv
filename,topic,subtopic,dim_0,dim_1,dim_2,...,dim_383
llm_01.md,LLM,Model Architecture,0.123456,-0.234567,0.345678,...,0.456789
math_01.md,Math,Linear Algebra,0.234567,-0.345678,0.456789,...,0.567890
fruit_01.md,Fruit,Citrus,0.345678,-0.456789,0.567890,...,0.678901
...
```

**Columns:**
- `filename`: The name of the document file
- `topic`: The main topic category (LLM, Math, or Fruit)
- `subtopic`: The specific subtopic within the category
- `dim_0` through `dim_767`: The embedding vector dimensions (768 dimensions for the bge-base-en-v1.5 model)

**Usage:**
This file can be loaded into Jupyter notebooks or Pandas DataFrames for further analysis:

```python
import pandas as pd

# Load embeddings
df = pd.read_csv('embeddings.csv')

# Get embedding vectors (all columns after 'subtopic')
embedding_columns = [col for col in df.columns if col.startswith('dim_')]
embeddings = df[embedding_columns].values

# Get metadata
metadata = df[['filename', 'topic', 'subtopic']]

# Example: Find documents by topic
llm_docs = df[df['topic'] == 'LLM']
```

## similarity_results.csv

This file contains pairwise similarity scores between all documents. The results are sorted by similarity score (highest to lowest).

**Format:**
```csv
document1_filename,document1_topic,document1_subtopic,document2_filename,document2_topic,document2_subtopic,similarity_score,same_topic
llm_01.md,LLM,Model Architecture,llm_02.md,LLM,Prompt Design,0.856234,true
math_01.md,Math,Linear Algebra,math_02.md,Math,Calculus,0.823456,true
llm_03.md,LLM,Text Processing,llm_04.md,LLM,RAG Systems,0.798765,true
fruit_01.md,Fruit,Citrus,fruit_02.md,Fruit,Berries,0.734521,true
llm_01.md,LLM,Model Architecture,math_01.md,Math,Linear Algebra,0.456789,false
...
```

**Columns:**
- `document1_filename`: Name of the first document in the pair
- `document1_topic`: Topic of the first document
- `document1_subtopic`: Subtopic of the first document
- `document2_filename`: Name of the second document in the pair
- `document2_topic`: Topic of the second document
- `document2_subtopic`: Subtopic of the second document
- `similarity_score`: Cosine similarity score (0 to 1, where 1 is most similar)
- `same_topic`: Boolean indicating if both documents share the same topic

**Usage:**
This file can be used for various analyses:

```python
import pandas as pd

# Load similarity results
similarities = pd.read_csv('similarity_results.csv')

# Find most similar cross-topic pairs
cross_topic = similarities[similarities['same_topic'] == 'false']
most_similar_cross = cross_topic.head(10)

# Calculate average similarity within topics
within_topic = similarities[similarities['same_topic'] == 'true']
avg_by_topic = within_topic.groupby('document1_topic')['similarity_score'].mean()

# Find similar documents for a specific file
doc_similarities = similarities[
    (similarities['document1_filename'] == 'llm_01.md') |
    (similarities['document2_filename'] == 'llm_01.md')
]
```

## TF-IDF CSV Outputs

The TF-IDF analysis script generates six CSV files for comprehensive term frequency and document analysis.

### tf.csv

This file contains the term frequency matrix in wide format (one row per document, one column per term).

**Format:**
```csv
document,topic,subtopic,term1,term2,term3,...,termN
fruit_01.md,Fruit,Citrus,10,6,1,...,0
fruit_02.md,Fruit,Berries,0,4,0,...,1
...
```

**Columns:**
- `document`: The name of the document file
- `topic`: The main topic category
- `subtopic`: The specific subtopic
- Followed by one column for each unique term in the corpus with its frequency count

**Note:** This format is not recommended for large corpora as it creates a very wide matrix. Use `tf_sparse.csv` instead for better efficiency.

### tf_sparse.csv

This file contains term frequency data in sparse format, only storing non-zero entries.

**Format:**
```csv
document_id,term_id,frequency
0,0,10
0,1624,6
1,1624,4
...
```

**Columns:**
- `document_id`: Numeric ID of the document (use document_index.csv to look up the filename)
- `term_id`: Numeric ID of the term (use term_index.csv to look up the term text)
- `frequency`: Raw frequency count of the term in the document

**Usage:**
```python
import pandas as pd

# Load all related files
tf_sparse = pd.read_csv('tf_sparse.csv')
doc_index = pd.read_csv('document_index.csv')
term_index = pd.read_csv('term_index.csv')

# Join to get readable results
tf_readable = tf_sparse \
    .merge(doc_index, on='document_id') \
    .merge(term_index, on='term_id')

# Find all terms in a specific document
doc_terms = tf_readable[tf_readable['document'] == 'fruit_01.md']
print(doc_terms[['term', 'frequency', 'idf_weight']].sort_values('frequency', ascending=False))
```

### idf.csv

This file contains inverse document frequency scores for all terms, sorted by IDF weight.

**Format:**
```csv
term,idf_weight,collection_frequency
citrus,3.258097,1
overview,3.258097,1
...
topic,0.039221,25
```

**Columns:**
- `term`: The term text
- `idf_weight`: The IDF weight (higher = more distinctive/rare)
- `collection_frequency`: Number of documents containing this term

**Sorting:** Terms are sorted by `idf_weight` in descending order, so the most distinctive terms appear first.

### document_index.csv

This file maps numeric document IDs to document filenames and metadata.

**Format:**
```csv
document_id,document,topic,subtopic
0,fruit_01.md,Fruit,Citrus
1,fruit_02.md,Fruit,Berries
2,fruit_03.md,Fruit,Tropical
...
```

**Columns:**
- `document_id`: Numeric identifier for the document
- `document`: The document filename
- `topic`: The main topic category
- `subtopic`: The specific subtopic

### term_index.csv

This file maps numeric term IDs to terms, sorted by IDF weight.

**Format:**
```csv
term_id,term,idf_weight,collection_frequency
0,citrus,3.258097,1
1,overview,3.258097,1
2,group,3.258097,1
...
```

**Columns:**
- `term_id`: Numeric identifier for the term
- `term`: The term text
- `idf_weight`: The IDF weight (higher = more distinctive/rare)
- `collection_frequency`: Number of documents containing this term

**Sorting:** Terms are sorted by `idf_weight` in descending order, matching the sort order of `idf.csv`.

### term_documents.csv

This file is an inverted index showing which documents contain each term.

**Format:**
```csv
term_id,term,document_ids
0,citrus,0
1,overview,0
1624,fruits,0;1;2;3;4;5;6;7;8
...
```

**Columns:**
- `term_id`: Numeric identifier for the term
- `term`: The term text
- `document_ids`: Semicolon-separated list of document IDs that contain this term

**Usage:**
```python
import pandas as pd

# Load the inverted index
term_docs = pd.read_csv('term_documents.csv')
doc_index = pd.read_csv('document_index.csv')

# Find all documents containing a specific term
term_row = term_docs[term_docs['term'] == 'fruits'].iloc[0]
doc_ids = [int(x) for x in term_row['document_ids'].split(';')]

# Look up the document names
matching_docs = doc_index[doc_index['document_id'].isin(doc_ids)]
print(f"Documents containing 'fruits':")
print(matching_docs[['document', 'topic', 'subtopic']])
```

## Console Output

The script continues to display the same printf-style console output as before, showing:
- Progress messages during processing
- Documents grouped by topic
- Top 20 most similar document pairs
- Average similarity within topics
- Average similarity across topics
- Export confirmation messages

This console output is preserved for real-time monitoring and quick analysis, while the CSV files provide structured data for deeper investigation.
